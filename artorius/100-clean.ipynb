{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install googletrans==3.1.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## root directory\n",
    "## the path before the current directory\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "path_data = os.path.join(root, 'data-tweet')\n",
    "# translator = Translator(service_urls=['translate.googleapis.com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the data\n",
    "df_vacc_us = pd.read_csv(os.path.join(path_data, 'US COVID-19 Tweets.csv'), usecols=['datetime', 'text'])\n",
    "df_vacc_id = pd.read_csv(os.path.join(path_data, 'indonesia-TRANSLATED-covid-sentiment.csv'), usecols=['date', 'translated'])\n",
    "df_vacc_in = pd.read_csv(os.path.join(path_data, 'india_covid_tweets_trans2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacc_id = (df_vacc_id.rename(columns={'translated': 'text'})\n",
    "                        .dropna(subset=['text'])\n",
    "                        .assign(country='id')\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacc_us.datetime = pd.to_datetime(df_vacc_us.datetime)\n",
    "df_vacc_us['date'] = df_vacc_us.datetime.dt.date\n",
    "df_vacc_us = df_vacc_us.assign(country='us')\n",
    "df_vacc_us.drop(columns=['datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacc_in = (df_vacc_in.melt(id_vars=['date'], \n",
    "                              value_vars=[i for i in df_vacc_in.columns if i.endswith('hashtags') != True and i != 'date'], \n",
    "                              var_name='userid', value_name='text'\n",
    "                              )\n",
    "                        .drop(columns=['userid'])\n",
    "                        .assign(country='in')\n",
    "                        .dropna(subset=['text'])\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_nonenglish_tweet(dataframe: pd.DataFrame, \n",
    "#                            target_col: str\n",
    "#                            ) -> pd.DataFrame:\n",
    "#     '''\n",
    "#     This function is to clean the non-english tweet\n",
    "#     '''\n",
    "    \n",
    "#     dataframe.target_col = dataframe.target_col.str.lower()\n",
    "#     dataframe = dataframe.dropna(subset=[target_col])\n",
    "#     dataframe['lang'] = dataframe[target_col].apply(lambda x: translator.detect(x).lang)\n",
    "#     dataframe = dataframe[dataframe.lang == 'en']\n",
    "    \n",
    "#     return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vacc_us = clean_nonenglish_tweet(df_vacc_us, 'text')\n",
    "# df_vacc_in = clean_nonenglish_tweet(df_vacc_in, 'text')\n",
    "# df_vacc_id = clean_nonenglish_tweet(df_vacc_id, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(dataframe: pd.DataFrame, \n",
    "                       target_col: str\n",
    "                      ) -> pd.DataFrame:\n",
    "    '''\n",
    "    This function is to perform the sentiment analysis\n",
    "    '''\n",
    "    \n",
    "    dataframe[target_col] = dataframe[target_col].str.lower() # lower case\n",
    "    dataframe['polarity'] = dataframe[target_col].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    dataframe['subjectivity'] = dataframe[target_col].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacc_id = sentiment_analysis(df_vacc_id, 'text')\n",
    "df_vacc_in = sentiment_analysis(df_vacc_in, 'text')\n",
    "df_vacc_us = sentiment_analysis(df_vacc_us, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.concat([df_vacc_id, df_vacc_in, df_vacc_us], ignore_index=True)\n",
    "df_tweets.drop(columns=['text'], inplace=True) # drop text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_csv(os.path.join(path_data, 'tweets.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8f43a7909c1c004417d38a2aae4808776198692c948156b64ab6dfc08b2a350"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
